# -*- coding: utf-8 -*-
"""genderclassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yJk4FlyWfoYBHFy2xb87gKX_EEpVIGnD
"""

import joblib
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
import xgboost as xgb
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns

x= pd.read_csv('/content/weight-height.csv')

x.head()

x.tail()

x.isnull()

x.describe()

x.info()

x

x.hist(bins=50, figsize=(20,15))
plt.show()

pd.value_counts(x['Gender']).plot.bar()

f,ax=plt.subplots(figsize=(9,9))
sns.heatmap(x.corr(),annot=True, linewidths=.5, fmt='.1f',ax=ax)

X = x.drop('Gender',axis=1)
Y = x['Gender']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)
clf = DecisionTreeClassifier()
clf.fit(X_train,Y_train)
y_predict = clf.predict(X_test)
acc1 = accuracy_score(Y_test, y_predict)
conf_matrix = confusion_matrix(Y_test, y_predict)
classification_rep = classification_report(Y_test, y_predict)

print(f'Accuracy: {acc1}')
print(f'Confusion Matrix:\n{conf_matrix}')
print(f'Classification Report:\n{classification_rep}')

model = LogisticRegression()
model.fit(X_train, Y_train)
y1_pred = model.predict(X_test)
acc2 = accuracy_score(Y_test, y1_pred)
conf_matrix = confusion_matrix(Y_test, y1_pred)
classification_rep = classification_report(Y_test, y1_pred)

print(f'Accuracy: {acc2}')
print(f'Confusion Matrix:\n{conf_matrix}')
print(f'Classification Report:\n{classification_rep}')

rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, Y_train)
y2_pred = rf_classifier.predict(X_test)
acc3 = accuracy_score(Y_test, y2_pred)
conf_matrix = confusion_matrix(Y_test, y2_pred)
classification_rep = classification_report(Y_test, y2_pred)
print(f'Accuracy: {acc3}')
print(f'Confusion Matrix:\n{conf_matrix}')
print(f'Classification Report:\n{classification_rep}')

param_grid = {'C': [0.1, 1, 10, 100],'gamma': [ 0.001, 0.01, 0.1, 1, 10],'kernel': ['linear']}
svm_classifier = SVC(random_state=42)
grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)

grid_search.fit(X_train, Y_train)

best_model = grid_search.best_estimator_
best_params = grid_search.best_params_
best_svm_classifier = SVC(**best_params, random_state=42)

best_svm_classifier.fit(X_train, Y_train)
y3_pred = best_svm_classifier.predict(X_test)
acc4 = accuracy_score(Y_test, y3_pred)
conf_matrix = confusion_matrix(Y_test, y3_pred)
classification_rep = classification_report(Y_test, y3_pred)

print(f'Best Parameters: {best_params}')
print(f'Accuracy: {acc4}')
print(f'Confusion Matrix:\n{conf_matrix}')
print(f'Classification Report:\n{classification_rep}')

best_model = grid_search.best_estimator_
best_params = grid_search.best_params_

# Step 4: Save the best model to a file
joblib.dump(best_model, 'best_model.sav')

# Optionally, you can also save the best parameters to a file
joblib.dump(best_params, 'best_parameters.sav')

knn_classifier = KNeighborsClassifier(n_neighbors=6)
knn_classifier.fit(X_train, Y_train)
y4_pred = knn_classifier.predict(X_test)
acc5 = accuracy_score(Y_test, y4_pred)
conf_matrix = confusion_matrix(Y_test, y4_pred)
classification_rep = classification_report(Y_test, y4_pred)

print(f'Accuracy: {acc5}')
print(f'Confusion Matrix:\n{conf_matrix}')
print(f'Classification Report:\n{classification_rep}')

nb_classifier = GaussianNB()
nb_classifier.fit(X_train, Y_train)
y5_pred = nb_classifier.predict(X_test)
acc6 = accuracy_score(Y_test, y5_pred)
conf_matrix = confusion_matrix(Y_test, y5_pred)
classification_rep = classification_report(Y_test, y5_pred)

# Print the results
print(f'Accuracy: {acc6}')
print(f'Confusion Matrix:\n{conf_matrix}')
print(f'Classification Report:\n{classification_rep}')

le = LabelEncoder()
Y_train_encoded = le.fit_transform(Y_train)
Y_test_encoded = le.transform(Y_test)
xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, max_depth=6, learning_rate=0.1, seed=42)
xgb_classifier.fit(X_train, Y_train_encoded, eval_set=[(X_test, Y_test_encoded)], verbose=10)
y6_pred = xgb_classifier.predict(X_test)
acc7 = accuracy_score(Y_test_encoded, y6_pred)
conf_matrix = confusion_matrix(Y_test_encoded, y6_pred)
classification_rep = classification_report(Y_test_encoded, y6_pred)

print(f'Accuracy: {acc7}')
print(f'Confusion Matrix:\n{conf_matrix}')
print(f'Classification Report:\n{classification_rep}')

classifiers = {
    'Decision Tree',
    'Logistic Regression',
    'Random Forest',
    'SVM',
    'KNN',
    'XG Boost',
    'Naive Bayes'
}
results=pd.DataFrame({'Model':['Decision Tree','Logistic Regression','Random Forest','SVM','KNN','XG Boost','Naive Bayes'],
                    'Accuracy Score':[acc1,acc2,acc3,acc4,acc5,acc6,acc7]})
result_df=results.sort_values(by='Accuracy Score', ascending=False)
result_df=result_df.set_index('Model')
result_df

Algorithms= ['Decision Tree','Logistic Regression','Random Forest','SVM','KNN','XG Boost','Naive Bayes']
Score= [acc1,acc2,acc3,acc4,acc5,acc6,acc7]
sns.set(rc={'figure.figsize':(15,8)})
plt.xlabel("Algorithms")
plt.ylabel("Accuracy score")
sns.barplot(x=Algorithms,y=Score)

from google.colab import files
files.download('best_model.sav')